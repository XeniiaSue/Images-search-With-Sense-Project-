# Images-search-With-Sense-Project
## Предыстория
Мы работаем в фотохостинге для профессиональных фотографов «Со Смыслом» (“With Sense”).

Наши пользователи размещают свои фотографии на хостинге и сопровождают их полным описанием: указывают место съёмок, модель камеры и т. д. Отличительная особенность сервиса — описание: его может предоставить не только тот, кто размещает фотографию, но и другие пользователи портала

Наш отдел занимается экспериментом по разработке поиска референсных фотографий для фотографов. Суть поиска заключается в следующем: пользователь сервиса вводит описание нужной сцены.

Чтобы эксперимент получил право на жизнь, нужно защитить его перед руководителем компании. Для защиты необходимо презентовать так называемый PoC (Proof of Concept, Проверка концепции) — продемонстрировать, что такой проект практически осуществим. Нам поручено разработать демонстрационную версию поиска изображений по запросу.

Для демонстрационной версии нужно выбрать лучшую модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — и покажет, насколько текст и картинка подходят друг другу.

На основе лучшей модели можно будет собрать предварительную версию продукта, которую вы покажете руководителю компании.
В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.

В папке `train_images` содержатся изображения для тренировки модели.

В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:

1. Имя файла изображения.
2. Идентификатор описания.
3. Доля людей, подтвердивших, что описание соответствует изображению.
4. Количество человек, подтвердивших, что описание соответствует изображению.
5. Количество человек, подтвердивших, что описание не соответствует изображению.

В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:

1. Имя файла изображения.
2. Идентификатор описания.

3, 4, 5 — оценки трёх экспертов.

Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.

В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.

В папке `test_images` содержатся изображения для тестирования модели.

## Итог
В рамках работы мы построили систему поиска изображений по текстовым запросам.

1. Подготовка данных

- Провели загрузку и очистку датасетов.

- Исключили изображения с «детскими» описаниями на основе словаря запрещённых слов, чтобы соблюсти законодательные ограничения.

- В качестве целевой переменной использовали усреднённые экспертные оценки, нормализованные в диапазон [0,1].

2. Векторизация

- Для изображений использовали предобученную сверточную сеть ResNet-18 (без финального слоя), что позволило получить компактные векторы по 512 признаков.

- Для текстов применили модель all-MiniLM-L6-v2 из библиотеки sentence-transformers, которая преобразует запросы в векторы размерностью 384 признака.

- Векторы изображений и текстов объединили, получив итоговую матрицу признаков размером (4079, 896).

3. Обучение моделей

- Для корректного разбиения на обучение и тестирование использовали GroupShuffleSplit, чтобы изображения не попадали одновременно в train и test.

- Были протестированы разные алгоритмы: DummyRegressor, RidgeCV, RandomForest, GradientBoosting, а также нейросети.

- Основной метрикой выбрали Spearman Rank Correlation, так как задача заключается не в точном предсказании числа, а в правильном упорядочивании изображений по релевантности.

4. Результаты

- Лучшей моделью оказалась усложнённая нейронная сеть (NeuralNet+), которая показала SpearmanR ≈ 0.62, что выше, чем у градиентного бустинга (≈0.50) и случайного леса (≈0.49). Это означает, что нейросеть наиболее точно сохраняет порядок релевантности при ранжировании изображений по тексту.

5. Тестирование

- Для эмбеддингов из test_images и случайных 10 запросов из test_queries модель выдавала наиболее релевантное изображение.

- Для запросов с запрещёнными словами вместо изображения возвращался дисклеймер, что соответствует требованиям законодательства.

- Нельзя сказать, что модель выводит всегда релевантные изображения, но иногда попадает.
